{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b50dbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./venv/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.9/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.9/site-packages (from nltk) (2024.11.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/texnedo/Documents/projects/mathematics-and-python/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5bb18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/texnedo/Documents/projects/mathematics-and-python/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package reuters to /Users/texnedo/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/texnedo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.corpus import reuters\n",
    "from collections import defaultdict\n",
    "from nltk.probability import FreqDist\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dad10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuters.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc4a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP response: 200\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://raw.githubusercontent.com/mmcky/nyu-econ-370/refs/heads/master/notebooks/data/book-war-and-peace.txt\")\n",
    "print(\"HTTP response: \" + str(response.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef091b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(words):\n",
    "    print(\"Number of words: \" + str(len(words)))\n",
    "\n",
    "    # Create trigrams\n",
    "    tri_grams = list(trigrams(words))\n",
    "\n",
    "    # Build a trigram model\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    # Count frequency of co-occurrence\n",
    "    for w1, w2, w3 in tri_grams:\n",
    "        model[(w1, w2)][w3] += 1\n",
    "\n",
    "    # Transform the counts into probabilities\n",
    "    for w1_w2 in model:\n",
    "        total_count = float(sum(model[w1_w2].values()))\n",
    "        for w3 in model[w1_w2]:\n",
    "            model[w1_w2][w3] /= total_count\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42907d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER I\\n\\n\"Well, Prince, so Genoa and Lucca are now just family estates of the\\nBuonapartes. But I w'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = response.text\n",
    "data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba6dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 700250\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "#words = nltk.word_tokenize(' '.join(reuters.words()))\n",
    "words_processed = nltk.word_tokenize(response.text.lower())\n",
    "words = []\n",
    "for word in words_processed:\n",
    "    words.append(word)\n",
    "    if word in ['.', '!', '?']:\n",
    "        words.append('<s>')\n",
    "model = create_model(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8161fdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " 'i',\n",
       " \"''\",\n",
       " 'well',\n",
       " ',',\n",
       " 'prince',\n",
       " ',',\n",
       " 'so',\n",
       " 'genoa',\n",
       " 'and',\n",
       " 'lucca',\n",
       " 'are',\n",
       " 'now',\n",
       " 'just',\n",
       " 'family',\n",
       " 'estates',\n",
       " 'of',\n",
       " 'the',\n",
       " 'buonapartes',\n",
       " '.',\n",
       " '<s>',\n",
       " 'but',\n",
       " 'i',\n",
       " 'warn',\n",
       " 'you',\n",
       " ',',\n",
       " 'if',\n",
       " 'you',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'tell',\n",
       " 'me',\n",
       " 'that',\n",
       " 'this',\n",
       " 'means',\n",
       " 'war',\n",
       " ',',\n",
       " 'if',\n",
       " 'you',\n",
       " 'still',\n",
       " 'try',\n",
       " 'to',\n",
       " 'defend',\n",
       " 'the',\n",
       " 'infamies',\n",
       " 'and',\n",
       " 'horrors',\n",
       " 'perpetrated',\n",
       " 'by',\n",
       " 'that',\n",
       " 'antichrist',\n",
       " '--',\n",
       " 'i',\n",
       " 'really',\n",
       " 'believe',\n",
       " 'he',\n",
       " 'is',\n",
       " 'antichrist',\n",
       " '--',\n",
       " 'i',\n",
       " 'will',\n",
       " 'have',\n",
       " 'nothing',\n",
       " 'more',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'you',\n",
       " 'and',\n",
       " 'you',\n",
       " 'are',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'my',\n",
       " 'friend',\n",
       " ',',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'my',\n",
       " \"'faithful\",\n",
       " 'slave',\n",
       " ',',\n",
       " \"'\",\n",
       " 'as',\n",
       " 'you',\n",
       " 'call',\n",
       " 'yourself',\n",
       " '!',\n",
       " '<s>',\n",
       " 'but',\n",
       " 'how',\n",
       " 'do',\n",
       " 'you',\n",
       " 'do',\n",
       " '?',\n",
       " '<s>',\n",
       " 'i',\n",
       " 'see',\n",
       " 'i',\n",
       " 'have']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dfab59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 700250\n"
     ]
    }
   ],
   "source": [
    "# Compute the frequency distribution\n",
    "fdist = FreqDist(words)\n",
    "\n",
    "# Total number of words in the corpus\n",
    "total_words = sum(fdist.values())\n",
    "\n",
    "print(\"Number of words: \" + str(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a37cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the next word\n",
    "def predict_next_word(w1, w2):\n",
    "    \"\"\"\n",
    "    Predicts the next word based on the previous two words using the trained trigram model.\n",
    "    Args:\n",
    "    w1 (str): The first word.\n",
    "    w2 (str): The second word.\n",
    "\n",
    "    Returns:\n",
    "    Tuple = (str: The predicted next word, float: Probability, object: All possible combinations)\n",
    "    \"\"\"\n",
    "    next_word = model[w1, w2]\n",
    "    if next_word:\n",
    "        predicted_word = max(next_word, key=next_word.get)  # Choose the most likely next word\n",
    "        return (predicted_word, next_word[predicted_word], next_word)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100d0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_freq(word):\n",
    "    if word not in fdist:\n",
    "        return None\n",
    "    count = fdist[word]\n",
    "    return count / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8771c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(probabilities):\n",
    "    \"\"\"\n",
    "    Calculate perplexity given an array of word probabilities in a sentence.\n",
    "    \n",
    "    Args:\n",
    "        probabilities (list or numpy.ndarray): Array of probabilities assigned by the model \n",
    "                                                to each word in the sentence. \n",
    "                                                Each probability should be a value between 0 and 1.\n",
    "                                                \n",
    "    Returns:\n",
    "        float: Perplexity score for the sentence.\n",
    "    \"\"\"\n",
    "    if not probabilities or any(p <= 0 or p > 1 for p in probabilities):\n",
    "        raise ValueError(\"Probabilities must be a non-empty array of values between 0 and 1.\")\n",
    "    \n",
    "    log_probs = np.log(probabilities)\n",
    "    avg_log_prob = np.mean(log_probs)\n",
    "    perplexity = np.exp(-avg_log_prob)\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "160c4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_token_without_punctuation(token):\n",
    "    \"\"\"\n",
    "    Check if a token contains no punctuation marks.\n",
    "    \n",
    "    Args:\n",
    "        token (str): The token to check.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the token has no punctuation, False otherwise.\n",
    "    \"\"\"\n",
    "    pattern = r\"^[^\\W_]*$\"\n",
    "    return bool(re.match(pattern, token, flags=re.UNICODE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea2c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generared sentence:  an adjutant to the emperor 's eyes .\n",
      "Perplexity score: 97.31231502375717\n",
      "Generared sentence:  with a smile .\n",
      "Perplexity score: 52.19213536274845\n",
      "Generared sentence:  too soon for news .\n",
      "Perplexity score: 198.3742569489315\n",
      "Generared sentence:  enough !\n",
      "Perplexity score: 502.8789177580497\n",
      "Generared sentence:  fine !\n",
      "Perplexity score: 355.58909286246904\n",
      "Generared sentence:  ca n't be helped !\n",
      "Perplexity score: 280.54356460286414\n",
      "Generared sentence:  since the ball .\n",
      "Perplexity score: 286.4503926591006\n",
      "Generared sentence:  followed by a new and unexpected steps .\n",
      "Perplexity score: 338.0348388954622\n",
      "Generared sentence:  how can you judge of it .\n",
      "Perplexity score: 124.07791464901662\n",
      "Generared sentence:  what is it ?\n",
      "Perplexity score: 80.33955022996527\n",
      "Generared sentence:  hardly had he not been for the first time .\n",
      "Perplexity score: 416.3258172198484\n",
      "Generared sentence:  listen !\n",
      "Perplexity score: 416.3258172198484\n",
      "Generared sentence:  can i do n't know what to do so .\n",
      "Perplexity score: 156.2319334439031\n",
      "Generared sentence:  like the others .\n",
      "Perplexity score: 143.99316535385836\n",
      "Generared sentence:  ours ?\n",
      "Perplexity score: 729.3388494325422\n",
      "Generared sentence:  nor could he be here in a whisper .\n",
      "Perplexity score: 295.21723842169695\n",
      "Generared sentence:  whom have you been to see him .\n",
      "Perplexity score: 194.9240066743199\n",
      "Generared sentence:  off with it .\n",
      "Perplexity score: 190.07036513787176\n",
      "Generared sentence:  been under fire .\n",
      "Perplexity score: 102.23160233455971\n",
      "Generared sentence:  did you get here ?\n",
      "Perplexity score: 100.24763982683474\n",
      "Generared sentence:  mary !\n",
      "Perplexity score: 152.07766283848764\n",
      "Generared sentence:  into the room .\n",
      "Perplexity score: 123.9542694617043\n",
      "Generared sentence:  still less did he say ?\n",
      "Perplexity score: 151.9637896193464\n",
      "Generared sentence:  armed with these words .\n",
      "Perplexity score: 925.7465324283469\n",
      "Generared sentence:  joseph alexeevich 's house .\n",
      "Perplexity score: 742.2485038587615\n",
      "Generared sentence:  takes after me !\n",
      "Perplexity score: 785.5219808880197\n",
      "Generared sentence:  lay me down !\n",
      "Perplexity score: 279.1230817306731\n",
      "Generared sentence:  moment by moment the door .\n",
      "Perplexity score: 189.84819046796972\n",
      "Generared sentence:  le charmant hippolyte was surprising by his own .\n",
      "Perplexity score: 544.6614961722686\n",
      "Generared sentence:  russian and french troops .\n",
      "Perplexity score: 184.12919235071706\n",
      "Generared sentence:  get along !\n",
      "Perplexity score: 207.8711594706022\n",
      "Generared sentence:  dinner was ready to cry .\n",
      "Perplexity score: 303.9275792386928\n",
      "Generared sentence:  where is he ?\n",
      "Perplexity score: 157.23023071614185\n",
      "Generared sentence:  four days previously .\n",
      "Perplexity score: 386.9989032052891\n",
      "Generared sentence:  why did n't you ?\n",
      "Perplexity score: 168.8611388600378\n",
      "Generared sentence:  man 's free will .\n",
      "Perplexity score: 113.90359180738771\n",
      "Generared sentence:  science does not know how to get away as quickly as possible .\n",
      "Perplexity score: 598.9548952512927\n",
      "Generared sentence:  cold shivers ran down his spine .\n",
      "Perplexity score: 335.5583598382592\n",
      "Generared sentence:  understand that .\n",
      "Perplexity score: 210.2401380537762\n",
      "Generared sentence:  men are his son 's fate is at stake .\n",
      "Perplexity score: 139.47351717896055\n",
      "Generared sentence:  read the letter .\n",
      "Perplexity score: 344.4741763398902\n",
      "Generared sentence:  tea !\n",
      "Perplexity score: 453.52132712006596\n",
      "Generared sentence:  again he glanced at her .\n",
      "Perplexity score: 147.50448613318852\n",
      "Generared sentence:  nothing !\n",
      "Perplexity score: 181.74811122703625\n",
      "Generared sentence:  spread out his hand .\n",
      "Perplexity score: 507.0522583431934\n",
      "Generared sentence:  herself a partner , fanning herself and her own room .\n",
      "Perplexity score: 216.86597778700101\n",
      "Generared sentence:  around him .\n",
      "Perplexity score: 298.61065145852587\n",
      "Generared sentence:  set your friend -- life and death .\n",
      "Perplexity score: 316.49582547313605\n",
      "Generared sentence:  write to her .\n",
      "Perplexity score: 502.8789177580497\n",
      "Generared sentence:  went the song .\n",
      "Perplexity score: 133.77492421869235\n"
     ]
    }
   ],
   "source": [
    "generated_count = 0\n",
    "used_trigrams = set()\n",
    "while generated_count < 50:\n",
    "    #i_word = words[random.randint(0, len(words) - 1)]\n",
    "    i_word = '<s>'\n",
    "    i_1_word = words[random.randint(0, len(words) - 1)]\n",
    "    #print(\"Stating from: [\" + i_word + \" \" + i_1_word + \"]\")\n",
    "    #if not is_token_without_punctuation(i_word) or not is_token_without_punctuation(i_1_word):\n",
    "    #    continue\n",
    "    if not is_token_without_punctuation(i_1_word):\n",
    "        continue\n",
    "    result = [i_word, i_1_word]\n",
    "    result_probs = [get_unigram_freq(i_word), get_unigram_freq(i_1_word)]\n",
    "    success = True\n",
    "    for i in range(2, 30):\n",
    "        text = predict_next_word(result[i - 2], result[i - 1])\n",
    "        if text is None:\n",
    "            success = False\n",
    "            break\n",
    "        current_trigram = (result[i - 2], result[i - 1], text[0])\n",
    "        if current_trigram in used_trigrams:\n",
    "            success = False\n",
    "            break \n",
    "        used_trigrams.add(current_trigram)\n",
    "        result.append(text[0])\n",
    "        if text[0] in {'.', '!', '?', ';'}:\n",
    "            break\n",
    "    if success:\n",
    "        score = calculate_perplexity(result_probs)\n",
    "        if score > 1000:\n",
    "            continue\n",
    "        sentence = ' '.join(result).replace('<s>', '')\n",
    "        print(\"Generared sentence: \" + sentence)\n",
    "        print(\"Perplexity score: {}\".format(score))\n",
    "        generated_count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60c27873",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"war\"\n",
    "result = predict_next_word(\"<s>\", input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f36037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('is', 1.0, defaultdict(<function create_model.<locals>.<lambda>.<locals>.<lambda> at 0x16a68e310>, {'is': 1.0}))\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7fc579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc361bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60551ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94679cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136f0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ccbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "920727a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngram_processing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4da6def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = get_tokenized_data(response.text, skip_words = {\"chapter\", \",\", \".\", \"'s\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f8cad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3202303"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80d7cde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50886"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68b64210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mother', 'and', 'the', 'youngest', 'daughter', '--', 'both', 'named', 'nataly', 'ever', 'since', 'the']\n",
      "['``', 'natalya', 'ilynichna', 'behaves', 'very', 'well', 'to', 'me', \"''\", 'remarked', 'boris', '``', 'i', 'have']\n",
      "['nataly', 'you', 'know', 'my', 'love', 'for', 'my', 'son', ':', 'i', 'would', 'do', 'anything', 'for', 'his']\n",
      "['``', 'that', 'is', 'with', 'ilya', 'rostov', 'who', 'married', 'nataly', 'shinshina', \"''\", 'said', 'anna']\n",
      "['never', 'could', 'understand', 'how', 'nataly', 'made', 'up', 'her', 'mind', 'to', 'marry', 'that']\n",
      "['``', 'nataly', \"''\", 'he', 'said', 'moving', 'with', 'rapid', 'steps', 'toward', 'her', '``', 'decide', 'my', 'fate']\n",
      "['``', 'natalya', 'ilynichna', \"''\", 'pierre', 'began', 'dropping', 'his', 'eyes', 'with', 'a', 'feeling', 'of']\n"
     ]
    }
   ],
   "source": [
    "for item in tokenized_data:\n",
    "    for word in item:\n",
    "        if \"nataly\" in word:\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cad548cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['continually', 'bringing', 'visitors', 'to', 'the', 'countess', 'rostova', 'big', 'house', 'on']\n",
      "['rostova', 'carriage', 'in', 'which', 'they', 'were', 'seated', 'drove', 'over', 'the', 'straw']\n",
      "['``', 'i', 'am', 'living', 'at', 'countess', 'rostova', \"''\", 'replied', 'boris', 'again', 'adding', '``', 'your']\n",
      "['vladimirovich', 'bezukhov', 'countess', 'rostova', 'sat', 'for', 'a', 'long', 'time', 'all', 'alone']\n",
      "['countess', 'rostova', 'with', 'her', 'daughters', 'and', 'a', 'large', 'number', 'of', 'guests', 'was']\n",
      "['theater', 'berg', 'had', 'pointed', 'out', 'vera', 'rostova', 'to', 'him', 'and', 'had', 'said', 'in']\n",
      "['livonian', 'gentleman', 'should', 'propose', 'marriage', 'to', 'a', 'countess', 'rostova', ';', 'but']\n",
      "['``', 'you', 'always', 'dance', 'i', 'have', 'a', 'protegee', 'the', 'young', 'rostova', 'here', 'ask', 'her', \"''\"]\n",
      "['pleasure', 'on', 'his', 'face', 'approached', 'countess', 'rostova']\n",
      "['little', 'rostova', 'is', 'very', 'charming', 'there', 'something', 'fresh', 'original', 'un-']\n",
      "['``', 'with', 'natasha', 'rostova', 'yes', '?', \"''\", 'said', 'he']\n",
      "['little', 'rostova', 'i', 'do', 'not', 'think', 'my', 'brother', 'will', 'ever', 'marry', 'again', 'and']\n",
      "['surprising', 'news', 'he', 'informed', 'her', 'of', 'his', 'engagement', 'to', 'natasha', 'rostova']\n",
      "['of', 'the', 'young', 'countess', 'rostova', 'the', 'old', 'prince', '(', 'who', 'apart', 'from', 'that', 'was']\n",
      "['``', 'ah', 'madam', '!', \"''\", 'he', 'began', '``', 'madam', 'countess', '...', 'countess', 'rostova', 'if', 'i', 'am', 'not']\n",
      "['anatole', 'had', 'lately', 'moved', 'to', 'dolokhov', 'the', 'plan', 'for', 'natalie', 'rostova']\n",
      "['loved', 'affianced', 'wife', '--', 'the', 'same', 'natasha', 'rostova', 'who', 'used', 'to', 'be', 'so']\n",
      "['the', 'weather', 'asked', 'if', 'he', 'had', 'heard', 'of', 'kuragin', 'abduction', 'of', 'rostova']\n",
      "['``', 'you', 'promised', 'countess', 'rostova', 'to', 'marry', 'her', 'and', 'were', 'about', 'to', 'elope', 'with']\n",
      "['breathe', 'a', 'word', 'of', 'what', 'has', 'passed', 'between', 'you', 'and', 'countess', 'rostova', 'i']\n",
      "['the', 'attempted', 'abduction', 'of', 'rostova', 'he', 'resolutely', 'denied', 'these', 'rumors']\n",
      "['``', 'i', 'have', 'received', 'a', 'refusal', 'from', 'countess', 'rostova', 'and', 'have', 'heard', 'reports']\n",
      "['``', 'so', 'monsieur', 'kuragin', 'has', 'not', 'honored', 'countess', 'rostova', 'with', 'his', 'hand', '?', \"''\"]\n",
      "['``', 'well', 'it', 'does', \"n't\", 'matter', \"''\", 'said', 'prince', 'andrew', '``', 'tell', 'countess', 'rostova']\n",
      "['compromise', 'the', 'young', 'countess', 'rostova', 'and', 'so', 'he', 'wanted', 'to', 'meet', 'kuragin']\n",
      "['``', 'that', 'rostova', 'the', 'one', 'who', '...', \"''\"]\n",
      "['taken', 'on', 'myself', 'the', 'role', 'of', 'natalie', 'rostova', 'knight', 'at', 'all', 'and', 'have']\n",
      "['natasha', 'rostova', '!', \"''\"]\n",
      "['``', 'no', ';', 'i', 'mean', 'do', 'you', 'know', 'natasha', 'rostova', '?', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "for item in tokenized_data:\n",
    "    for word in item:\n",
    "        if \"rostova\" in word:\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d7e6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_freq = 1\n",
    "train_data_processed, test_data_processed, vocabulary, word_counts = preprocess_data(tokenized_data, \n",
    "                                                                        tokenized_data, \n",
    "                                                                        minimum_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46319aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 34533)\n",
      "('and', 22208)\n",
      "('to', 16667)\n",
      "('of', 14885)\n",
      "('a', 10540)\n",
      "('he', 9999)\n",
      "(\"''\", 9010)\n",
      "('``', 8939)\n",
      "('in', 8779)\n",
      "('that', 8186)\n",
      "('his', 7984)\n",
      "('was', 7372)\n",
      "('with', 5663)\n",
      "('it', 5596)\n",
      "('had', 5373)\n",
      "('not', 4840)\n",
      "('her', 4725)\n",
      "('him', 4637)\n",
      "('at', 4531)\n",
      "('i', 4522)\n",
      "('but', 4045)\n",
      "('as', 4023)\n",
      "('on', 4000)\n",
      "('!', 3923)\n",
      "('you', 3793)\n",
      "('for', 3517)\n",
      "('she', 3488)\n",
      "('is', 3365)\n",
      "('?', 3136)\n",
      "('said', 2842)\n",
      "('all', 2785)\n",
      "('from', 2687)\n",
      "('be', 2438)\n",
      "('were', 2431)\n",
      "('what', 2390)\n",
      "('by', 2383)\n",
      "('they', 2251)\n",
      "('who', 2162)\n",
      "('one', 2119)\n",
      "('--', 2083)\n",
      "('this', 2073)\n",
      "('which', 2057)\n",
      "('have', 2002)\n",
      "('pierre', 1963)\n",
      "('prince', 1927)\n",
      "('so', 1861)\n",
      "('an', 1629)\n",
      "('do', 1564)\n",
      "('there', 1557)\n",
      "('up', 1553)\n",
      "('did', 1535)\n",
      "('them', 1528)\n",
      "('or', 1523)\n",
      "('when', 1494)\n",
      "('been', 1476)\n",
      "('...', 1447)\n",
      "('their', 1440)\n",
      "('no', 1396)\n",
      "('would', 1384)\n",
      "('now', 1332)\n",
      "('only', 1298)\n",
      "('if', 1292)\n",
      "('are', 1286)\n",
      "('me', 1273)\n",
      "('out', 1233)\n",
      "('my', 1225)\n",
      "('natasha', 1213)\n",
      "('man', 1189)\n",
      "(\"n't\", 1155)\n",
      "(';', 1145)\n",
      "('andrew', 1143)\n",
      "('could', 1124)\n",
      "('we', 1063)\n",
      "('will', 1060)\n",
      "('more', 1054)\n",
      "('himself', 1019)\n",
      "('about', 1010)\n",
      "('into', 1004)\n",
      "('how', 1002)\n",
      "(':', 975)\n",
      "('then', 941)\n",
      "('time', 927)\n",
      "('princess', 915)\n",
      "('face', 893)\n",
      "('french', 878)\n",
      "('went', 862)\n",
      "('know', 845)\n",
      "('some', 845)\n",
      "('after', 836)\n",
      "('before', 830)\n",
      "('eyes', 827)\n",
      "('your', 809)\n",
      "('old', 804)\n",
      "('very', 802)\n",
      "('men', 793)\n",
      "('rostov', 776)\n",
      "('thought', 766)\n",
      "('room', 758)\n",
      "('go', 751)\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "all_words_counts = []\n",
    "for i, j in word_counts.items():\n",
    "    all_words.append((i, j))\n",
    "    all_words_counts.append(j)\n",
    "indexes = np.argsort(all_words_counts)\n",
    "for i in range(1, 100):\n",
    "    print(all_words[indexes[-i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfc6d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing n-gram counts with n = 1 ...\n",
      "Computing n-gram counts with n = 2 ...\n",
      "Computing n-gram counts with n = 3 ...\n",
      "Computing n-gram counts with n = 4 ...\n",
      "Computing n-gram counts with n = 5 ...\n"
     ]
    }
   ],
   "source": [
    "n_gram_counts_list = []\n",
    "for n in range(1, 6):\n",
    "    print(\"Computing n-gram counts with n =\", n, \"...\")\n",
    "    n_model_counts = count_n_grams(train_data_processed, n)\n",
    "    n_gram_counts_list.append(n_model_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e21f2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('he', 0.010702405630815214), ('is', 0.0007039202945635694), ('i', 5.448700484934343e-05), ('i', 5.448700484934343e-05)]\n"
     ]
    }
   ],
   "source": [
    "previous_tokens = [\"natasha\", \"rostova\", \"and\", \"pierre\", \"bezukhov\", \"well\", ',','and', 'what']\n",
    "tmp_suggest = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=\"\")\n",
    "print(tmp_suggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9e55f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<e>', 0.0025009311977864097), ('and', 0.0003264062670003264), ('i', 5.448700484934343e-05), ('i', 5.448700484934343e-05)]\n"
     ]
    }
   ],
   "source": [
    "previous_tokens = [\"kutuzov\", \"'s\", \"staff\", \"officer\"]\n",
    "tmp_suggest = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=\"\")\n",
    "print(tmp_suggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78d4c56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('of', 0.003955738493612017), ('of', 0.00340374952725701), ('of', 0.0007612833061446438), ('i', 5.448700484934343e-05)]\n"
     ]
    }
   ],
   "source": [
    "previous_tokens = [\"pierre\", \"was\", \"so\", \"deep\", \"in\", \"thought\", \"of\", \"the\", \"battle\"]\n",
    "tmp_suggest = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=\"\")\n",
    "print(tmp_suggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cffa5f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 0.0009202620040058464), ('and', 0.000326477309826967), ('and', 0.0001633808953273064), ('i', 5.448700484934343e-05)]\n"
     ]
    }
   ],
   "source": [
    "previous_tokens = [\"natasha\", \"was\", \"in\", \"a\", \"state\", \"of\", \"affairs\"]\n",
    "tmp_suggest = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=\"\")\n",
    "print(tmp_suggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d8e2634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 0.0014519251451925144), ('and', 0.0004883872368135446), ('at', 0.00010896807235480004), ('at', 0.00010896807235480004)]\n"
     ]
    }
   ],
   "source": [
    "previous_tokens = [\"natasha\", \"and\", \"pierre\", \"were\", \"living\", \"in\", \"petersburg\"]\n",
    "tmp_suggest = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=\"\")\n",
    "print(tmp_suggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73019f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
